{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "import cerberus\n",
    "import schema\n",
    "import codecs\n",
    "import pprint \n",
    "\n",
    "## k value for sample file \n",
    "k = 50 \n",
    "\n",
    "## Function for iterating through the main tags \n",
    "def extract_context(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\" This function takes an osm_file or a XML file as an argument. \n",
    "        It is used to iter through the tags and specifically dive into node, way and relation tags \n",
    "        and extract information from them. \n",
    "        \n",
    "        The iter process gets everything from start to end of the tag e.g. lat, long, id, <tag k value> \n",
    "    \"\"\"\n",
    "    ## Get elements from start to end\n",
    "    context_1 = iter(ET.iterparse(osm_file, events=('start','end')))\n",
    "    _, root = next(context_1)\n",
    "    for event,elem in context_1:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem  \n",
    "            root.clear()\n",
    "\n",
    "## Create the new sample file \n",
    "with open('Melbourne_Map_Sample.xml', 'wb') as output:\n",
    "    output.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n')\n",
    "    output.write('<osm>\\n  ')\n",
    "    \n",
    "    for i,element in enumerate(extract_context('Melbourne_Map')):\n",
    "        if i % k == 0:\n",
    "            output.write(ET.tostring(element, encoding='utf-8'))\n",
    "    \n",
    "    output.write('</osm>')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'node': 1}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get an idea of all the different tags in the dataset \n",
    "## Returns tag name and count of each \n",
    "def count_tags(filename):\n",
    "    \"\"\" A function where the new sample file is passed as an argument and returns tags. \n",
    "        This is to get an understanding of what to iter through further during the data\n",
    "        cleaning process, get an understanding of what to look into and how many of each\n",
    "        unique tag there is. \"\"\"\n",
    "\n",
    "    tags = {}\n",
    "    parser = ET.iterparse(filename) \n",
    "    for __, elem in parser:\n",
    "         ## Add 1 to each unique tag found\n",
    "        if elem.tag in tags:\n",
    "            tags[elem.tag] += 1\n",
    "        else:\n",
    "             tags[elem.tag] = 1\n",
    "                \n",
    "        elem.clear()\n",
    "        del parser\n",
    "        return tags \n",
    "\n",
    "count_tags(\"Melbourne_Map_Sample.xml\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['shop', 'restriction', 'maxspeed', 'golf', 'office', 'building:part', 'man_made', 'indoor', 'lcn', 'destination:forward', 'postal_code', 'motorcycle', 'seats', 'service:bicycle:rental', 'is_in', 'addr:housenumber', 'removed:railway', 'bollard', 'not_served_by', 'proposed', 'addr:state', 'bench', 'source', 'drive_in', 'location', 'crossing:barrier', 'fuel', 'covered', 'image', 'bin', 'conveying', 'maxspeed:source', 'junction', 'to', 'emergency', 'source:name', 'material', 'leisure', 'dismount', 'motor_vehicle', 'foot', 'height', 'tourism', 'addr:street', 'monitoring:bicycle', 'fixme', 'name:en', 'vending', 'name', 'designation', 'level', 'tram', 'addr:postcode', 'internet_access:fee', 'public_transport', 'crossing', 'gauge', 'sidewalk', 'kerb', 'name:es', 'internet_access', 'payment:mastercard', 'bicycle', 'usage', 'ref:unimelb', 'roof:height', 'cutting', 'frequency', 'route_ref', 'parking', 'traffic_signals:sound', 'todo', 'source:addr', 'capacity', 'barrier', 'display', 'source:oneway', 'wikipedia', 'access', 'religion', 'toll', 'check_date', 'boundary', 'ref', 'email', 'highway', 'service:bicycle:repair', 'source:maxspeed', 'power', 'contact:email', 'electrified', 'denomination', 'operator:website', 'microbrewery', 'segregated', 'footway', 'addr:inclusion', 'country', 'route', 'atm', 'source:geometry', 'addr:city', 'payment:visa_debit', 'place', 'residential', 'toilets:wheelchair', 'service:bicycle:retail', 'destination', 'bridge', 'addr:housename', 'contact:website', 'survey:date', 'amenity', 'wifi', 'created_by', 'opening_date', 'operator', 'horse', 'from', 'service', 'area', 'button_operated', 'opening_hours', 'support', 'diet:vegetarian', 'direction', 'landmark:name', 'layer', 'width', 'public_transport:version', 'building:material', 'stars', 'motorcar', 'waste', 'type', 'bicycle_parking', 'website', 'admin_level', 'entrance', 'lanes', 'alt_name', 'bus', 'brand', 'removed:name', 'service:bicycle:pump', 'visibility', 'phone', 'train', 'maxheight', 'old_name', 'smoking', 'incline', 'traffic_calming', 'tunnel', 'voltage', 'start_date', 'route_master', 'dispensing', 'headway', 'landuse', 'colour', 'maxheight:source', 'crossing_ref', 'addr:interpolation', 'backrest', 'addr:suburb', 'surface', 'source:opening_hours', 'wikidata', 'payment:notes', 'attribution', 'waterway', 'cables', 'species', 'cuisine', 'sport', 'short_name', 'opening_date:source', 'building:levels', 'switch', 'cycleway', 'lit', 'name:fr', 'wires', 'description', 'information', 'shelter', 'oneway', 'payment:visa', 'wheelchair_toilet', 'levels', 'old_name:1', 'faculty', 'payment:maestro', 'railway', 'network', 'building', 'building:colour', 'natural', 'payment:coins', 'crossing:light', 'wheelchair', 'outdoor_seating', 'building_number', 'circuits', 'tactile_paving', 'construction', 'takeaway', 'floating', 'addr:country'])\n"
     ]
    }
   ],
   "source": [
    "## Get all unique k values \n",
    "## Returns names of different k values\n",
    "def extract_k_values(filename):\n",
    "    \"\"\"\n",
    "    Takes a XML file as an argument and returns all k values from ways and nodes tags. The\n",
    "    function first steps into the node, way or relation tag and then steps into the \"tag\" tag\n",
    "    and extracts their values. Returns a set of all different values found. Examples are values such as \n",
    "    addr:city, country and amenity. \n",
    "    \"\"\"\n",
    "    osm_file = open(filename,\"r\")\n",
    "    name_types = set()\n",
    "    for __, elem in ET.iterparse(filename, events=(\"start\",)):\n",
    "        \n",
    "        if elem.tag == \"node\" or elem.tag == \"way\" or elem.tag == \"relation\":\n",
    "            for tag in elem.iter('tag'):\n",
    "                try:\n",
    "                    name_types.add(tag.attrib['k'])\n",
    "                except KeyError:\n",
    "                    continue \n",
    "                        \n",
    "    print name_types\n",
    "\n",
    "extract_k_values('Melbourne_Map_Sample.xml') \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "addr:postcode \n",
      "\n",
      "3000: 20\n",
      "3002: 1\n",
      "3003: 11\n",
      "3004: 2\n",
      "3006: 1\n",
      "3008: 1\n",
      "3011: 3\n",
      "3013: 3\n",
      "3031: 2\n",
      "3032: 3\n",
      "3040: 1\n",
      "3051: 8\n",
      "3052: 2\n",
      "3053: 5\n",
      "3054: 2\n",
      "3055: 6\n",
      "3056: 3\n",
      "3057: 11\n",
      "3065: 8\n",
      "3066: 11\n",
      "3067: 4\n",
      "3068: 11\n",
      "3070: 3\n",
      "3121: 5\n",
      "3141: 1\n",
      "3205: 5\n",
      "3206: 1\n",
      "3207: 3\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "## Regex characters for searching the last word for the value of the given k\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "value_types = defaultdict(int)\n",
    "\n",
    "def audit_value_type(value_types, street_name): \n",
    "    \"\"\" \n",
    "    Using regex characters above to get the given phrase. In this case the last character of a string. \n",
    "    Function takes two arguments street_types and street_name. Value types is a dictionary \n",
    "    keeping track of all the different values found and a count of each. \n",
    "    \"\"\"\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        value_type = m.group()\n",
    "        value_types[value_type] += 1\n",
    "\n",
    "## print function for printing k values\n",
    "def print_sorted_dict(d):\n",
    "    keys = d.keys()\n",
    "    keys = sorted(keys, key=lambda s:s.lower())\n",
    "    for k in keys:\n",
    "        v = d[k]\n",
    "        print \"%s: %d\" % (k,v)\n",
    "\n",
    "## Checks whether or not k exists \n",
    "def is_name(elem, name_type):\n",
    "    return (elem.attrib['k'] == name_type)\n",
    "\n",
    "## Goes through tags and prints values for a given name type e.g. addr:city or addr:postcode\n",
    "def audit_tags(name_type):\n",
    "    \"\"\"\n",
    "    Takes a k value argument e.g. addr:city and prints all the distinct values and their count. \n",
    "    See use of it below. Using is_name() checks whether the name_type exists. If it exists\n",
    "    then it uses audit_value_type() to make a dictionary of all distinct tag values. \n",
    "    The dictionary is then printed using printed_sorted_dict(). \n",
    "    \"\"\"\n",
    "    osm_file = open(\"Melbourne_Map_Sample.xml\") \n",
    "    print name_type, \"\\n\"\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "        if elem.tag == \"way\" or elem.tag == \"node\" or elem.tag == \"relation\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_name(tag, name_type):\n",
    "                    audit_value_type(value_types, tag.attrib['v'])\n",
    "    \n",
    "    osm_file.close() \n",
    "    print_sorted_dict(value_types)\n",
    "    value_types.clear()\n",
    "\n",
    "## Searching through k-values randomly or ones that are common in having errors \n",
    "\n",
    "## audit_tags('addr:country')\n",
    "## audit_tags('postal_code')\n",
    "## audit_tags('exit_to')\n",
    "## audit_tags('addr:city')\n",
    "audit_tags('addr:postcode')\n",
    "## audit_tags('amenity')\n",
    "## audit_tags('addr:state')\n",
    "## audit_tags('phone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "## Set name for csv files to which XML data will be exported\n",
    "NODES_PATH = \"nodes.csv\"\n",
    "NODE_TAGS_PATH = \"nodes_tags.csv\"\n",
    "WAYS_PATH = \"ways.csv\"\n",
    "WAY_NODES_PATH = \"ways_nodes.csv\"\n",
    "WAY_TAGS_PATH = \"ways_tags.csv\"\n",
    "\n",
    "## Search for colon (:) and problemchars \n",
    "LOWER_COLON = re.compile(r'^([a-z]|_)+:([a-z]|_)+')\n",
    "PROBLEMCHARS = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "## Set which keys/values will be extracted from tag\n",
    "NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']\n",
    "\n",
    "## Clean up any inconsistency found through querying or earlier through trial and error checking\n",
    "## Returns new{}, a dictionary with the new cleaned data \n",
    "def clean_tag(element,secondary,default_tag_type):\n",
    "    \"\"\" \n",
    "    This function is where the main cleaning happens. A dictionary called new{} is created. \n",
    "    Arguments passed into the function are element, secondary and default_tag_type. \n",
    "    elements are parent tags e.g. node, way and secondary are secondary tags such as \"tag\". The key and type\n",
    "    are extracted using secondary.attrib['k']. \n",
    "    \n",
    "    The key value is checked based on if there was a inconsistency found earlier or later through \n",
    "    database querying. For example, if new['key'] == 'state' we step into the secondary value, \n",
    "    put the original value from the XML file in a variable and replace that variable with the new desired \n",
    "    name/iterm, e.g. 'VIC' is replaced with 'Victoria'. \n",
    "    \"\"\"\n",
    "    new = {}\n",
    "    new['id'] = element.attrib['id']\n",
    "    if \":\" not in secondary.attrib['k']:\n",
    "        new['key'] = secondary.attrib['k']\n",
    "        new['type'] = default_tag_type \n",
    "    \n",
    "    else:\n",
    "        post_colon = secondary.attrib['k'].index(\":\") + 1\n",
    "        new['key'] = secondary.attrib['k'][post_colon:]\n",
    "        new['type'] = secondary.attrib['k'][:post_colon-1]\n",
    "    \n",
    "    ## Clean inconsistency in addr:state \n",
    "    if new['key'] == 'state':\n",
    "        original_value = secondary.attrib['v']\n",
    "        if original_value == 'VIC' or original_value == 'VICTORIA':\n",
    "            original_value = \"Victoria\"\n",
    "        \n",
    "        new['value'] = original_value \n",
    "    \n",
    "    ## Clean up inconsistency in sources (Inconsistent in lower and upper case)\n",
    "    elif new['key'] == 'source':\n",
    "        original_value = secondary.attrib['v']\n",
    "        if original_value == 'survey;yahoo':\n",
    "            original_value = 'survey;Yahoo'\n",
    "        if original_value == 'yahoo':\n",
    "            original_value = 'Yahoo'\n",
    "        if original_value == 'bing':\n",
    "            original_value = 'Bing'\n",
    "            \n",
    "        new['value'] = original_value\n",
    "    \n",
    "    ## Handle whitespace in phone numbers \n",
    "    elif new['key'] == 'phone':\n",
    "        original_value = secondary.attrib['v']\n",
    "        if (' ' in original_value) == True:\n",
    "            original_value = original_value.replace(\" \",\"\") \n",
    "        \n",
    "        if ('613' in original_value) == True:\n",
    "            original_value = original_value.replace(\"613\",\"\")\n",
    "            \n",
    "        new['value'] = original_value\n",
    "    else:\n",
    "        new['value'] = secondary.attrib['v']\n",
    "    \n",
    "    return new \n",
    "\n",
    "class UnicodeDictWriter(csv.DictWriter, object):\n",
    "    \"\"\"Extend csv.DictWriter to handle Unicode input\"\"\"\n",
    "\n",
    "    def writerow(self, row):\n",
    "        super(UnicodeDictWriter, self).writerow({\n",
    "            k: (v.encode('utf-8') if isinstance(v, unicode) else v) for k, v in row.iteritems()\n",
    "        })\n",
    "\n",
    "    def writerows(self, rows):\n",
    "        for row in rows:\n",
    "            self.writerow(row)\n",
    "\n",
    "## Iterates through the parent tag e.g. node and gets all wanted attributes \n",
    "def shape_element(element,node_attr_fields=NODE_FIELDS,way_attr_fields=WAY_FIELDS,problem_chars=PROBLEMCHARS,\n",
    "                 default_tag_type='regular'):\n",
    "    \"\"\" \n",
    "    Iterate through node and way tags and all secondary tags. Use clean_tag() then to clean secondary tag\n",
    "    values and return the new clean dictionary of values.  \n",
    "    \"\"\"\n",
    "    \n",
    "    node_attribs = {}\n",
    "    way_attribs = {}\n",
    "    way_nodes = []\n",
    "    tags = []\n",
    "    \n",
    "    ## Getting attributes in node tags\n",
    "    if element.tag == \"node\":\n",
    "        for attrib,value in element.attrib.iteritems():\n",
    "            if attrib in node_attr_fields:\n",
    "                node_attribs[attrib] = value\n",
    "        \n",
    "        for secondary in element.iter():\n",
    "            if secondary.tag == 'tag':\n",
    "                if problem_chars.match(secondary.attrib['k']) is not None:\n",
    "                    continue\n",
    "                else:\n",
    "                    ## Using clean_tag to make sure data is cleaned up\n",
    "                    new = clean_tag(element, secondary, default_tag_type)\n",
    "                    if new is not None:\n",
    "                        tags.append(new)\n",
    "    \n",
    "        return {'node':node_attribs, 'node_tags':tags}\n",
    "    \n",
    "    ## Getting attributes in way tags\n",
    "    if element.tag==\"way\":\n",
    "        for attrib,value in element.attrib.iteritems():\n",
    "            if attrib in way_attr_fields:\n",
    "                way_attribs[attrib] = value\n",
    "        \n",
    "        counter = 0\n",
    "        for secondary in element.iter():\n",
    "            if secondary.tag == \"tag\":\n",
    "                if problem_chars.match(secondary.attrib['k']) is not None:\n",
    "                    continue\n",
    "                else:\n",
    "                    new = clean_tag(element, secondary, default_tag_type)\n",
    "                    if new is not None:\n",
    "                        tags.append(new)\n",
    "            \n",
    "            if secondary.tag == 'nd':\n",
    "                newnd = {}\n",
    "                newnd['id'] = element.attrib['id']\n",
    "                newnd['node_id'] = secondary.attrib['ref']\n",
    "                newnd['position'] = counter\n",
    "                counter += 1\n",
    "                way_nodes.append(newnd)\n",
    "        \n",
    "        return {'way':way_attribs, 'way_nodes':way_nodes, 'way_tags':tags} \n",
    "    \n",
    "## Export data to csv files\n",
    "def process_map(file_in, validate):\n",
    "    \"\"\"\n",
    "    Function for exporting data csv files. Takes output file name as argument. Uses shape_element \n",
    "    to iterate through all node and way tags. New data is then written in the csv file. \n",
    "    \"\"\"\n",
    "    with codecs.open(NODES_PATH, \"w\") as nodes_file,codecs.open(NODE_TAGS_PATH, \"w\") as nodes_tags_file,codecs.open(WAYS_PATH, \"w\") as ways_file, codecs.open(WAY_NODES_PATH, \"w\") as way_nodes_file,codecs.open(WAY_TAGS_PATH, \"w\") as way_tags_file:\n",
    "            \n",
    "        nodes_writer = UnicodeDictWriter(nodes_file, NODE_FIELDS)\n",
    "        node_tags_writer = UnicodeDictWriter(nodes_tags_file, NODE_TAGS_FIELDS)\n",
    "        ways_writer = UnicodeDictWriter(ways_file, WAY_FIELDS)\n",
    "        way_tags_writer = UnicodeDictWriter(way_tags_file, WAY_TAGS_FIELDS)\n",
    "        way_nodes_writer = UnicodeDictWriter(way_nodes_file, WAY_NODES_FIELDS)\n",
    "        \n",
    "        nodes_writer.writeheader()\n",
    "        node_tags_writer.writeheader()\n",
    "        ways_writer.writeheader()\n",
    "        way_nodes_writer.writeheader()\n",
    "        way_tags_writer.writeheader()\n",
    "        \n",
    "        validator = cerberus.Validator()\n",
    "        \n",
    "        for element in extract_context(file_in, tags=('node', 'way')):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                \n",
    "                if element.tag == 'node':\n",
    "                    nodes_writer.writerow(el['node'])\n",
    "                    node_tags_writer.writerows(el['node_tags'])\n",
    "                elif element.tag=='way':\n",
    "                    ways_writer.writerow(el['way'])\n",
    "                    way_nodes_writer.writerows(el['way_nodes'])\n",
    "                    way_tags_writer.writerows(el['way_tags'])\n",
    "\n",
    "\n",
    "process_map(\"Melbourne_Map_Sample.xml\", validate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "sqlite_file = \"mydv.db\"\n",
    "conn = sqlite3.connect(sqlite_file)\n",
    "cur = conn.cursor() \n",
    "\n",
    "## Load nodes.csv into database\n",
    "cur.execute('DROP TABLE IF EXISTS nodes')\n",
    "conn.commit()\n",
    "cur.execute(''' CREATE TABLE nodes(id INTEGER, lat FLOAT, lon FLOAT, user TEXT, uid INTEGER, version INTEGER,\n",
    "            changeset INTEGER, timestamp TEXT)''')\n",
    "conn.commit()\n",
    "with open(\"nodes.csv\", \"rb\") as fin:\n",
    "    dr = csv.DictReader(fin)\n",
    "    to_db = [(i['id'].decode(\"utf-8\"), i['lat'].decode(\"utf-8\"), i['lon'].decode(\"utf-8\"), \n",
    "              i['user'].decode(\"utf-8\"), i['uid'].decode(\"utf-8\"),i['version'].decode(\"utf-8\"),\n",
    "              i['changeset'].decode(\"utf-8\"),i['timestamp']) for i in dr]\n",
    "cur.executemany(\"INSERT INTO nodes(id,lat,lon,user,uid,version,changeset,timestamp) VALUES(?,?,?,?,?,?,?,?);\", to_db)\n",
    "conn.commit() \n",
    "\n",
    "## Load ways_nodes.csv into database\n",
    "cur.execute('DROP TABLE IF EXISTS ways_nodes')\n",
    "conn.commit()\n",
    "cur.execute(''' CREATE TABLE ways_nodes(id INTEGER, node_id INTEGER, position INTEGER)''')\n",
    "conn.commit()\n",
    "with open(\"ways_nodes.csv\", \"rb\") as fin:\n",
    "    dr = csv.DictReader(fin)\n",
    "    to_db = [(i['id'].decode(\"utf-8\"), i['node_id'].decode(\"utf-8\"), i['position'].decode(\"utf-8\")) for i in dr]\n",
    "cur.executemany(\"INSERT INTO ways_nodes(id,node_id,position) VALUES(?,?,?);\", to_db)\n",
    "conn.commit() \n",
    "\n",
    "## Load ways_tags.csv into database\n",
    "cur.execute('DROP TABLE IF EXISTS ways_tags')\n",
    "conn.commit()\n",
    "cur.execute('''CREATE TABLE ways_tags(id INTEGER,key TEXT,value TEXT,type TEXT)''')\n",
    "conn.commit()\n",
    "with open(\"ways_tags.csv\", \"rb\") as fin:\n",
    "    dr = csv.DictReader(fin)\n",
    "    to_db = [(i['id'].decode(\"utf-8\"), i['key'].decode(\"utf-8\"),i['value'].decode(\"utf-8\"),i['type'].decode(\"utf-8\")) for i in dr]\n",
    "cur.executemany(\"INSERT INTO ways_tags(id,key,value,type) VALUES(?,?,?,?);\", to_db)\n",
    "conn.commit() \n",
    "\n",
    "## Load ways.csv into database\n",
    "cur.execute('DROP TABLE IF EXISTS ways')\n",
    "conn.commit()\n",
    "cur.execute(''' CREATE TABLE ways(id INTEGER, user TEXT, uid INTEGER, version INTEGER, changeset INTEGER, timestamp TEXT)''')\n",
    "conn.commit()\n",
    "with open(\"ways.csv\", \"rb\") as fin:\n",
    "    dr = csv.DictReader(fin)\n",
    "    to_db = [(i['id'].decode(\"utf-8\"),i['uid'].decode(\"utf-8\"), i['user'].decode(\"utf-8\"),i['version'].decode(\"utf-8\"), i['changeset'].decode(\"utf-8\"), i['timestamp'].decode(\"utf-8\")) for i in dr]\n",
    "cur.executemany(\"INSERT INTO ways(id, uid, user, version, changeset, timestamp) VALUES(?,?,?,?,?,?);\", to_db)\n",
    "conn.commit()\n",
    "\n",
    "## Load nodes_tags.csv into database \n",
    "cur.execute('DROP TABLE IF EXISTS nodes_tags')\n",
    "conn.commit()\n",
    "cur.execute('''CREATE TABLE nodes_tags(id INTEGER,key TEXT,value TEXT,type TEXT, FOREIGN KEY (id) REFERENCES nodes(id)) ''')\n",
    "conn.commit() \n",
    "with open(\"nodes_tags.csv\",'rb') as fin:\n",
    "    dr = csv.DictReader(fin)\n",
    "    to_db = [(i['id'].decode(\"utf-8\"), i['key'].decode(\"utf-8\"), i['value'].decode(\"utf-8\"), i['type'].decode(\"utf-8\")) for i in dr]\n",
    "cur.executemany(\"INSERT INTO nodes_tags(id,key,value,type) VALUES(?,?,?,?);\",to_db)\n",
    "conn.commit() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users\n",
      "257 \n",
      "\n",
      "Number of nodes\n",
      "4687 \n",
      "\n",
      "Number of ways\n",
      "815 \n",
      "\n",
      "Different users\n",
      "[(u'Canley', 605), (u'Leon K', 561), (u'melb_guy', 514), (u'AlexOnTheBus', 338), (u'stevage', 230), (u'matthewsheffield', 193), (u'Mikideez', 176), (u'woowoowoo', 144), (u'Neil Penman', 143), (u'Pizza1016', 130)] \n",
      "\n",
      "Amenities in Melbourne from nodes_tags\n",
      "[(u'amenity', u'atm', 1), (u'amenity', u'bank', 2), (u'amenity', u'bar', 2), (u'amenity', u'bbq', 1), (u'amenity', u'bench', 8), (u'amenity', u'bicycle_parking', 7), (u'amenity', u'bureau_de_change', 1), (u'amenity', u'cafe', 22), (u'amenity', u'car_wash', 1), (u'amenity', u'college', 1)] \n",
      "\n",
      "Number of different amenities from nodes_tags\n",
      "120 \n",
      "\n",
      "Amenities in Melbourne from ways_tags\n",
      "[(u'amenity', u'bank', 1), (u'amenity', u'cafe', 1), (u'amenity', u'casino', 1), (u'amenity', u'conference_centre', 1), (u'amenity', u'doctors', 1), (u'amenity', u'fuel', 1), (u'amenity', u'hospital', 1), (u'amenity', u'parking', 19), (u'amenity', u'place_of_worship', 1), (u'amenity', u'public_building', 2), (u'amenity', u'school', 2), (u'amenity', u'shelter', 2), (u'amenity', u'theatre', 1), (u'amenity', u'university', 1)] \n",
      "\n",
      "Number of different amenities from ways_tags\n",
      "35 \n",
      "\n",
      "Sources in Melbourne from nodes_tags\n",
      "[(u'source', u'Bing', 2), (u'source', u'Collected via KeypadMapper', 2), (u'source', u'GPS', 1), (u'source', u'http://yarratrams.com.au/using-trams/service-changes/service-changes/2015/route-55-network-upgrade-work-saturday-23-to-friday-29-may/', 1), (u'source', u'https://www.ptv.vic.gov.au/live-travel-updates/article/route-55-temporary-tram-stop-closure-from-monday-13-february-2017-to-late-2019/', 1), (u'source', u'nearmap', 7), (u'source', u'survey', 9)] \n",
      "\n",
      "Number of different sources from nodes_tags\n",
      "23 \n",
      "\n",
      "Sources in Melbourne from ways_tags\n",
      "[(u'source', u'nearmap', 66), (u'source', u'Yahoo', 44), (u'source', u'Bing', 29), (u'source', u'survey', 11), (u'source', u'MMBW', 8), (u'source', u'default residential speed limit in Australia', 4), (u'source', u'ABS2011', 3), (u'source', u'GPS', 2), (u'source', u'bing,collins 1936', 2), (u'source', u'bing,knowledge', 2), (u'source', u'Direct', 1), (u'source', u'NearMap', 1), (u'source', u'Not a physical path - pedestrians are allowed to cross the traffic island!  This is to improve walking routes.', 1), (u'source', u'Yahoo Tracing', 1), (u'source', u'collins 1936', 1), (u'source', u'extrapolation', 1), (u'source', u'https://www.vicroads.vic.gov.au/~/media/files/documents/business-and-industry/heavyvehiclesheightclearanceunderstructureforpermitvehicles.pdf?la=en', 1), (u'source', u'nearmap;bing', 1), (u'source', u'photo', 1), (u'source', u'yahoo trace', 1), (u'source', u'yahoo; MMBW', 1)] \n",
      "\n",
      "Number of different sources from ways_tags\n",
      "182 \n",
      "\n",
      "Networks in Melbourne from nodes_tags\n",
      "[(u'network', u'PTV - Metropolitan Trams', 32), (u'network', u'PTV - Metropolitan Buses', 12), (u'network', u'PTV - Metropolitan Trains', 3), (u'network', u'PTV', 2), (u'network', u'PTV - Regional Trains', 1)] \n",
      "\n",
      "Number of different networks from nodes_tags\n",
      "50 \n",
      "\n",
      "Networks in Melbourne from ways_tags\n",
      "[(u'network', u'S', 15), (u'network', u'PTV - Metropolitan Trams', 8)] \n",
      "\n",
      "Number of different network from ways_tags\n",
      "23 \n",
      "\n",
      "Phone numbers ways_tags\n",
      "[(u'phone', u'+61131314', 1), (u'phone', u'+86098221', 1), (u'phone', u'+93881319', 1), (u'phone', u'+94189800', 1), (u'phone', u'+94825482', 1), (u'phone', u'+96893092', 1), (u'phone', u'1300364133', 1)] \n",
      "\n",
      "Phone numbers nodes_tags\n",
      "[(u'phone', u'+84150700', 1), (u'phone', u'+92994044', 1), (u'phone', u'+93282829', 1), (u'phone', u'+93292599', 1), (u'phone', u'+93810404', 1), (u'phone', u'+94160458', 1), (u'phone', u'+94160917', 1), (u'phone', u'+94171601', 1), (u'phone', u'+94172600', 1), (u'phone', u'+94172917', 1), (u'phone', u'+94174253', 1), (u'phone', u'+94177557', 1), (u'phone', u'+94193000', 1), (u'phone', u'+94198233', 1), (u'phone', u'+94291488', 1), (u'phone', u'+94863883', 1), (u'phone', u'+94897037', 1), (u'phone', u'+96025622', 1), (u'phone', u'+96299300', 1), (u'phone', u'+96399600', 1), (u'phone', u'+96423272', 1), (u'phone', u'+96603777', 1), (u'phone', u'+96623888', 1), (u'phone', u'+96636263', 1), (u'phone', u'+96852900', 1), (u'phone', u'+96865223', 1), (u'phone', u'+96902390', 1), (u'phone', u'+96960051\\u200e', 1), (u'phone', u'+99734159', 1), (u'phone', u'0393477922', 1), (u'phone', u'0394196118', 1), (u'phone', u'0394198600', 1), (u'phone', u'0396022228', 1), (u'phone', u'0396294111', 1), (u'phone', u'0396297405', 1), (u'phone', u'0398272608', 1), (u'phone', u'0\\\\96461117', 1), (u'phone', u'96704442', 1)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Number of unique users\n",
    "cur.execute(\"SELECT COUNT(DISTINCT(uid)) FROM (SELECT uid FROM nodes UNION ALL SELECT uid FROM ways);\")\n",
    "all_uid = cur.fetchall()\n",
    "print \"Number of unique users\"\n",
    "print all_uid[0][0], \"\\n\" \n",
    "\n",
    "cur.execute(\"SELECT uid, COUNT(uid) FROM (SELECT uid FROM nodes UNION ALL SELECT uid FROM ways)\")\n",
    "\n",
    "## Number of nodes\n",
    "cur.execute(\"SELECT COUNT(*) FROM nodes;\")\n",
    "all_nodes = cur.fetchall()\n",
    "print \"Number of nodes\"\n",
    "print all_nodes[0][0], \"\\n\"\n",
    "\n",
    "## Number of ways \n",
    "cur.execute(\"SELECT COUNT(*) FROM ways;\")\n",
    "all_ways = cur.fetchall()\n",
    "print \"Number of ways\"\n",
    "print all_ways[0][0], \"\\n\" \n",
    "\n",
    "## Top ten contributing users\n",
    "cur.execute(\"SELECT e.user, COUNT(*) as num FROM (SELECT user FROM nodes UNION ALL SELECT user FROM ways) e GROUP BY e.user ORDER BY num DESC LIMIT 10;\")\n",
    "all_vals = cur.fetchall()\n",
    "print \"Different users\"\n",
    "print all_vals, \"\\n\"\n",
    "\n",
    "## Different amenities in nodes_tags\n",
    "cur.execute(\"SELECT key,value, COUNT(value) FROM nodes_tags WHERE key ='amenity' GROUP BY value LIMIT 10\")\n",
    "all_rows = cur.fetchall()\n",
    "print \"Amenities in Melbourne from nodes_tags\"\n",
    "print all_rows, \"\\n\" \n",
    "\n",
    "cur.execute(\"SELECT COUNT(*) FROM nodes_tags WHERE key='amenity' \") \n",
    "all_tours = cur.fetchall()\n",
    "print \"Number of different amenities from nodes_tags\"\n",
    "print all_tours[0][0], \"\\n\"\n",
    "\n",
    "## Different amenities in ways_tags\n",
    "cur.execute(\"SELECT key,value, COUNT(value) FROM ways_tags WHERE key ='amenity' GROUP BY value\")\n",
    "all_rows = cur.fetchall()\n",
    "print \"Amenities in Melbourne from ways_tags\"\n",
    "print all_rows, \"\\n\" \n",
    "\n",
    "cur.execute(\"SELECT COUNT(*) FROM ways_tags WHERE key='amenity' \") \n",
    "all_tours = cur.fetchall()\n",
    "print \"Number of different amenities from ways_tags\"\n",
    "print all_tours[0][0], \"\\n\"\n",
    "\n",
    "## Different sources in nodes_tags\n",
    "cur.execute(\"SELECT key,value, COUNT(value) FROM nodes_tags WHERE key ='source' GROUP BY value\")\n",
    "all_rows = cur.fetchall()\n",
    "print \"Sources in Melbourne from nodes_tags\"\n",
    "print all_rows, \"\\n\" \n",
    "\n",
    "cur.execute(\"SELECT COUNT(*) FROM nodes_tags WHERE key='source' \") \n",
    "all_rows = cur.fetchall()\n",
    "print \"Number of different sources from nodes_tags\"\n",
    "print all_rows[0][0], \"\\n\"\n",
    "\n",
    "## Different sources in ways_tags\n",
    "cur.execute(\"SELECT key,value, COUNT(value) FROM ways_tags WHERE key ='source' GROUP BY value ORDER BY COUNT(value) DESC\")\n",
    "all_rows = cur.fetchall()\n",
    "print \"Sources in Melbourne from ways_tags\"\n",
    "print all_rows, \"\\n\" \n",
    "\n",
    "cur.execute(\"SELECT COUNT(*) FROM ways_tags WHERE key='source' \") \n",
    "all_tours = cur.fetchall()\n",
    "print \"Number of different sources from ways_tags\"\n",
    "print all_tours[0][0], \"\\n\"\n",
    "\n",
    "## Different networks in nodes_tags\n",
    "cur.execute(\"SELECT key,value, COUNT(value) FROM nodes_tags WHERE key ='network' GROUP BY value ORDER BY COUNT(value) DESC\")\n",
    "all_rows = cur.fetchall()\n",
    "print \"Networks in Melbourne from nodes_tags\"\n",
    "print all_rows, \"\\n\" \n",
    "\n",
    "cur.execute(\"SELECT COUNT(*) FROM nodes_tags WHERE key='network' \") \n",
    "all_rows = cur.fetchall()\n",
    "print \"Number of different networks from nodes_tags\"\n",
    "print all_rows[0][0], \"\\n\"\n",
    "\n",
    "## Different sources in ways_tags\n",
    "cur.execute(\"SELECT key,value, COUNT(value) FROM ways_tags WHERE key ='network' GROUP BY value ORDER BY COUNT(value) DESC\")\n",
    "all_rows = cur.fetchall()\n",
    "print \"Networks in Melbourne from ways_tags\"\n",
    "print all_rows, \"\\n\" \n",
    "\n",
    "cur.execute(\"SELECT COUNT(*) FROM ways_tags WHERE key='network' \") \n",
    "all_rows = cur.fetchall()\n",
    "print \"Number of different network from ways_tags\"\n",
    "print all_rows[0][0], \"\\n\"\n",
    "\n",
    "## Phone number inconsistency \n",
    "cur.execute(\"SELECT key,value, COUNT(value) FROM ways_tags WHERE key ='phone' GROUP BY value ORDER BY COUNT(value) DESC\")\n",
    "all_rows = cur.fetchall()\n",
    "print \"Phone numbers ways_tags\"\n",
    "print all_rows, \"\\n\"\n",
    "\n",
    "cur.execute(\"SELECT key,value, COUNT(value) FROM nodes_tags WHERE key ='phone' GROUP BY value ORDER BY COUNT(value) DESC\")\n",
    "all_rows = cur.fetchall()\n",
    "print \"Phone numbers nodes_tags\"\n",
    "print all_rows, \"\\n\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
